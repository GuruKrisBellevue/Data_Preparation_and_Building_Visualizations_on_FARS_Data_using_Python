{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed5592c",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Extracting-Data-from-API\" data-toc-modified-id=\"1.-Extracting-Data-from-API-1\">1. Extracting Data from API</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Overview-of-the-steps-in-this-Project:\" data-toc-modified-id=\"Overview-of-the-steps-in-this-Project:-1.0.1\">Overview of the steps in this Project:</a></span><ul class=\"toc-item\"><li><span><a href=\"#i.-In-this-project,-data-about-crashes-from-2021-across-the-US-is-extracted-from-NHTSA-API-https://crashviewer.nhtsa.dot.gov/CrashAPI.\" data-toc-modified-id=\"i.-In-this-project,-data-about-crashes-from-2021-across-the-US-is-extracted-from-NHTSA-API-https://crashviewer.nhtsa.dot.gov/CrashAPI.-1.0.1.1\">i. In this project, data about crashes from 2021 across the US is extracted from NHTSA API-<a href=\"https://crashviewer.nhtsa.dot.gov/CrashAPI\" rel=\"nofollow\" target=\"_blank\">https://crashviewer.nhtsa.dot.gov/CrashAPI</a>.</a></span></li><li><span><a href=\"#ii.-The-API-has-a-limit-of-upto-5000-records-in-one-pull.-Hence-the-data-is-pulled-in-multiple-iterations-and-they-are-pulled-in-such-a-way-there-is-no-data-loss.\" data-toc-modified-id=\"ii.-The-API-has-a-limit-of-upto-5000-records-in-one-pull.-Hence-the-data-is-pulled-in-multiple-iterations-and-they-are-pulled-in-such-a-way-there-is-no-data-loss.-1.0.1.2\">ii. The API has a limit of upto 5000 records in one pull. Hence the data is pulled in multiple iterations and they are pulled in such a way there is no data loss.</a></span></li><li><span><a href=\"#iii.-All-the-extracted-data-is-then-combined-and-then-transformations-are-applied-to-the-data.\" data-toc-modified-id=\"iii.-All-the-extracted-data-is-then-combined-and-then-transformations-are-applied-to-the-data.-1.0.1.3\">iii. All the extracted data is then combined and then transformations are applied to the data.</a></span></li></ul></li><li><span><a href=\"#Creating-dataframes-using-Dynamic-variables-for-each-API-Call\" data-toc-modified-id=\"Creating-dataframes-using-Dynamic-variables-for-each-API-Call-1.0.2\">Creating dataframes using Dynamic variables for each API Call</a></span></li></ul></li></ul></li><li><span><a href=\"#2.-Transformations\" data-toc-modified-id=\"2.-Transformations-2\">2. Transformations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transformation-1:-Concatenate-Dataframes\" data-toc-modified-id=\"Transformation-1:-Concatenate-Dataframes-2.1\">Transformation 1: Concatenate Dataframes</a></span></li><li><span><a href=\"#Transformation-2:-Checking-for-Nulls\" data-toc-modified-id=\"Transformation-2:-Checking-for-Nulls-2.2\">Transformation 2: Checking for Nulls</a></span></li><li><span><a href=\"#Transformation-3:-Change-column-names-to-upper-case\" data-toc-modified-id=\"Transformation-3:-Change-column-names-to-upper-case-2.3\">Transformation 3: Change column names to upper case</a></span></li><li><span><a href=\"#Transformation-4:-Convert-to-number\" data-toc-modified-id=\"Transformation-4:-Convert-to-number-2.4\">Transformation 4: Convert to number</a></span></li><li><span><a href=\"#Transformation-5:-Convert-to-Upper-Case\" data-toc-modified-id=\"Transformation-5:-Convert-to-Upper-Case-2.5\">Transformation 5: Convert to Upper Case</a></span></li><li><span><a href=\"#Transformation-6:-Adding-new-column-by-extracting-county-number\" data-toc-modified-id=\"Transformation-6:-Adding-new-column-by-extracting-county-number-2.6\">Transformation 6: Adding new column by extracting county number</a></span></li><li><span><a href=\"#Transformation-7:-Cleansing-CountyName-using-Regex\" data-toc-modified-id=\"Transformation-7:-Cleansing-CountyName-using-Regex-2.7\">Transformation 7: Cleansing CountyName using Regex</a></span></li><li><span><a href=\"#Transformation-8:-Cleansing-Date\" data-toc-modified-id=\"Transformation-8:-Cleansing-Date-2.8\">Transformation 8: Cleansing Date</a></span></li><li><span><a href=\"#Transformation-9:-Converting-Epoch-Date-to-Timestamp\" data-toc-modified-id=\"Transformation-9:-Converting-Epoch-Date-to-Timestamp-2.9\">Transformation 9: Converting Epoch Date to Timestamp</a></span></li><li><span><a href=\"#Transformation-10:-Changing-the-timestamp-format-and-order-of-columns\" data-toc-modified-id=\"Transformation-10:-Changing-the-timestamp-format-and-order-of-columns-2.10\">Transformation 10: Changing the timestamp format and order of columns</a></span></li><li><span><a href=\"#Transformation-11:-GroupBy-and-Sort-Transformations\" data-toc-modified-id=\"Transformation-11:-GroupBy-and-Sort-Transformations-2.11\">Transformation 11: GroupBy and Sort Transformations</a></span></li><li><span><a href=\"#Transformation-12:-GroupBy-and-Sort-Transformations-on-Crash-Date\" data-toc-modified-id=\"Transformation-12:-GroupBy-and-Sort-Transformations-on-Crash-Date-2.12\">Transformation 12: GroupBy and Sort Transformations on Crash Date</a></span></li></ul></li><li><span><a href=\"#3.-Displaying-data-of-the-final-dataframe\" data-toc-modified-id=\"3.-Displaying-data-of-the-final-dataframe-3\">3. Displaying data of the final dataframe</a></span></li><li><span><a href=\"#4.-Ethical-Implications\" data-toc-modified-id=\"4.-Ethical-Implications-4\">4. Ethical Implications</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#a.-Maximum-number-of-vehicles-involved-in-the-accident-is-restricted-to-six-vehicles.-Hence,-this-study-does-not-include-crashes-that-involved-more-than-6-vehicles-and-pileups.-This-should-be-taken-into-consideration-while-deriving-conclusions-from-the-research.\" data-toc-modified-id=\"a.-Maximum-number-of-vehicles-involved-in-the-accident-is-restricted-to-six-vehicles.-Hence,-this-study-does-not-include-crashes-that-involved-more-than-6-vehicles-and-pileups.-This-should-be-taken-into-consideration-while-deriving-conclusions-from-the-research.-4.0.0.1\">a. Maximum number of vehicles involved in the accident is restricted to six vehicles. Hence, this study does not include crashes that involved more than 6 vehicles and pileups. This should be taken into consideration while deriving conclusions from the research.</a></span></li><li><span><a href=\"#b.-All-the-rows-in-the-dataset-represents-the-crashes-that-had-atleast-one-fatality.-Hence-the-research-does-not-include-the-details-of-non-fatal-accidents.-The-grim-results--of-this-research-must-be-studied-with-empathy.\" data-toc-modified-id=\"b.-All-the-rows-in-the-dataset-represents-the-crashes-that-had-atleast-one-fatality.-Hence-the-research-does-not-include-the-details-of-non-fatal-accidents.-The-grim-results--of-this-research-must-be-studied-with-empathy.-4.0.0.2\">b. All the rows in the dataset represents the crashes that had atleast one fatality. Hence the research does not include the details of non-fatal accidents. The grim results  of this research must be studied with empathy.</a></span></li><li><span><a href=\"#c.-Some-crashes-did-not-had-include-the-time-of-crash-and-hence-they-were-replaced-with-default-values.-There-were-about-300-such-instances.-Hence,-the-results-cannot-be-derived-only-based-on-the-time-of-crash-as-about-1%-of-data-contains-default-values.\" data-toc-modified-id=\"c.-Some-crashes-did-not-had-include-the-time-of-crash-and-hence-they-were-replaced-with-default-values.-There-were-about-300-such-instances.-Hence,-the-results-cannot-be-derived-only-based-on-the-time-of-crash-as-about-1%-of-data-contains-default-values.-4.0.0.3\">c. Some crashes did not had include the time of crash and hence they were replaced with default values. There were about 300 such instances. Hence, the results cannot be derived only based on the time of crash as about 1% of data contains default values.</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d470e20",
   "metadata": {},
   "source": [
    "# Extracting data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Required libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request,urllib.parse,urllib.error\n",
    "import ssl\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33ad167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting global options for the notebook such as maxrows\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d13b6b",
   "metadata": {},
   "source": [
    "## 1. Extracting Data from API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35f241",
   "metadata": {},
   "source": [
    "#### Overview of the steps in this Project:\n",
    "##### i. In this project, data about crashes from 2021 across the US is extracted from NHTSA API-https://crashviewer.nhtsa.dot.gov/CrashAPI.\n",
    "##### ii. The API has a limit of upto 5000 records in one pull. Hence the data is pulled in multiple iterations and they are pulled in such a way there is no data loss.\n",
    "##### iii. All the extracted data is then combined and then transformations are applied to the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d953de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the base url to pull the crash API Data\n",
    "base_url=\"https://crashviewer.nhtsa.dot.gov/CrashAPI/crashes/GetCaseList?\"\n",
    "# The states are combined in such a way there is no data loss and also the number of records pulled \n",
    "# does not exceed 5000. Data from some states such as California, Texas are pulled by themselves due to \n",
    "# large number of records. Details about the state indices are present in the API documentation.\n",
    "list_of_state_iters=[\n",
    "    \"1,2,4,5,8,9,10,11,15,16,18\",\n",
    "    \"6\", # California\n",
    "    \"12\", # Florida\n",
    "    \"13,17,19,20,21,23,30\",\n",
    "    \"22,24,25,26,27,28,29\",\n",
    "    \"31,32,33,34,35,37,38,39\",\n",
    "    \"36,40,41,42,44,45,46\",\n",
    "    \"47,49,50,51,53,54,55,56\",\n",
    "    \"48\" # Texas\n",
    "     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4a45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crash_url(idx3):\n",
    "    \"\"\"\n",
    "    This function will loop through the state list and generate the URL for each API call. \n",
    "    It takes the index of iteration as an input and returns the URL\n",
    "    \"\"\"\n",
    "    # Extracting each item in the state iters list\n",
    "    state_list=list_of_state_iters[idx3]\n",
    "    # Setting up parameters to be used in the API. \n",
    "    fromYear=2021\n",
    "    toYear=2021\n",
    "    minNumOfVehicles=1\n",
    "    # Maximum number of vehicles involved in crash are set to 6\n",
    "    maxNumOfVehicles=6\n",
    "    output_format=\"json\"\n",
    "    params={'fromYear':fromYear,'toYear':toYear,\"minNumOfVehicles\":minNumOfVehicles,\n",
    "            \"maxNumOfVehicles\":maxNumOfVehicles,\"format\":output_format,\"states\":state_list}\n",
    "    # Framing the url for API call using the base url and Parameters used above\n",
    "    crash_url=base_url+urllib.parse.urlencode(params)\n",
    "    return crash_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a1b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_API_Data(crash_url):\n",
    "    \"\"\"\n",
    "    This function is used to extract the data from the crash API. This wil be called multiple times as the\n",
    "    API limit is set to 5000. \n",
    "    The function return the data in JSON format along with number of records in each call.\n",
    "    \"\"\"\n",
    "    # Including the API call within try-except call \n",
    "    try:\n",
    "        # Getting the API response using urllib\n",
    "        url_response=urllib.request.urlopen(crash_url)\n",
    "    # Handling HTTPError exceptions\n",
    "    except urllib.error.HTTPError as error1:\n",
    "        print(\"Sorry could not retrieve the crash details. Pleasae try again!\")\n",
    "        return None\n",
    "    # Handling URLError Exceptions\n",
    "    except urllib.error.URLError as error2:\n",
    "        print(\"Failed to reach the server\")\n",
    "        print(f\"Reason: {error2.reason}\" )\n",
    "    # If there are no exceptions, proceeding to processing the extracted data\n",
    "    else:\n",
    "        url_data=url_response.read()\n",
    "        # Reading the data in JSON format\n",
    "        json_data=json.loads(url_data)\n",
    "        # Reading the responses in Message and Count variables\n",
    "        message=json_data['Message']\n",
    "        ret_count=json_data['Count']\n",
    "        ret_count=int(ret_count)\n",
    "        # Checking for success message and validating if the data pull was successful\n",
    "        if (message==\"Results returned successfully\") & (ret_count > 0) :\n",
    "            print(f\"Data Retrieval success! {ret_count} values successfully retrieved from the API Call\")\n",
    "            # If the data pull was success, returning the data for further processing\n",
    "            return json_data[\"Results\"][0],ret_count\n",
    "        # If the data pull was not successful, return None\n",
    "        else:\n",
    "            print(f\"Error!Something is not right! Please recheck the inputs!\")\n",
    "            return None,None\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d705dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(idx3):\n",
    "    \"\"\"\n",
    "    This function extracts all the required field from API response and creates Dataframe \n",
    "    from the data extracted from API. It takes the index of iteration as an input and returns the URL.\n",
    "    \"\"\"\n",
    "    # Calling create URL function to create crash URL for each iteration.\n",
    "    crash_url=create_crash_url(idx3)\n",
    "    # Extracting the data from API with the URL created in above step\n",
    "    try:\n",
    "        API_results_data,extracted_count=extract_API_Data(crash_url)\n",
    "    except TypeError:\n",
    "        print(\"None Data returned from API!\")\n",
    "        return None\n",
    "    # Validating the number of records pulled and the number returned by the API. \n",
    "    # Also checking if the response is not None\n",
    "    if (len(API_results_data)==extracted_count) & (extracted_count != None) :\n",
    "        # These are the fields that the API returns\n",
    "        field_list=[\"CountyName\",\"CrashDate\",\"Fatals\",\"Peds\",\"Persons\",\"St_Case\",\"State\",\"StateName\",\"TotalVehicles\"]\n",
    "        # Creating a dataframe with random numbers with the number of Rows equal to the number of records returned by the \n",
    "        # API call. number of columns is the number of fields in the Field list\n",
    "        crash_API_df1=pd.DataFrame(np.random.rand(extracted_count,len(field_list)),columns=field_list)\n",
    "        # Populating the dataframe with the data extracted from the API by looping through the number of rows extracted.\n",
    "        for idx1 in range(extracted_count):\n",
    "            # For each row in the API call, each row in the dataframe is replaced.\n",
    "            for idx2,field in enumerate(field_list):\n",
    "                    # Using the pandas iloc to identify the row and column index to substitute the values\n",
    "                    crash_API_df1.iloc[idx1,idx2]=API_results_data[idx1][field]\n",
    "        # Returning the formatted Dataframe\n",
    "        return crash_API_df1\n",
    "    # If the counts from the API response does not match or if it is None, throws an error\n",
    "    else:\n",
    "        print(\"Extracted count does not match with the count of records in dataset! Please verify!\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc803b54",
   "metadata": {},
   "source": [
    "#### Creating dataframes using Dynamic variables for each API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0291c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Retrieval success! 4922 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 4922 values successfully retrieved from the API Call\n",
      "Created Dataframe #1\n",
      "Data Retrieval success! 3971 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 3971 values successfully retrieved from the API Call\n",
      "Created Dataframe #2\n",
      "Data Retrieval success! 3446 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 3446 values successfully retrieved from the API Call\n",
      "Created Dataframe #3\n",
      "Data Retrieval success! 4667 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 4667 values successfully retrieved from the API Call\n",
      "Created Dataframe #4\n",
      "Data Retrieval success! 4953 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 4953 values successfully retrieved from the API Call\n",
      "Created Dataframe #5\n",
      "Data Retrieval success! 4604 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 4604 values successfully retrieved from the API Call\n",
      "Created Dataframe #6\n",
      "Data Retrieval success! 4780 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 4780 values successfully retrieved from the API Call\n",
      "Created Dataframe #7\n",
      "Data Retrieval success! 4026 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 4026 values successfully retrieved from the API Call\n",
      "Created Dataframe #8\n",
      "Data Retrieval success! 4057 values successfully retrieved from the API Call\n",
      "Data Retrieval success! 4057 values successfully retrieved from the API Call\n",
      "Created Dataframe #9\n"
     ]
    }
   ],
   "source": [
    "# Getting the number of items in the states iters list. \n",
    "list_of_state_iters_len=len(list_of_state_iters)\n",
    "# Looping through the number of items in the list. An API call will be made for each iteration.\n",
    "for idx3 in range(list_of_state_iters_len):\n",
    "    if create_dataframe(idx3) is not None:\n",
    "        # Creating tables using dynamic variable in the format API_df_<index number> starting from 0 through 8\n",
    "        globals()[f\"API_rawDF_{idx3}\"]=create_dataframe(idx3)\n",
    "        # Printing confirmation message\n",
    "        print(f\"Created Dataframe #{idx3+1}\")\n",
    "        # Assigning name attribute for each dataframe\n",
    "        globals()[f\"API_rawDF_{idx3}\"].name=f\"API_rawDF_{idx3}\"\n",
    "    else:\n",
    "        print(\"None Object Returned! Exiting!\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91f54f",
   "metadata": {},
   "source": [
    "## 2. Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34997538",
   "metadata": {},
   "source": [
    "### Transformation 1: Concatenate Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d938b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of Combined Dataframe API_concat_rawDF is (39426, 9)\n"
     ]
    }
   ],
   "source": [
    "# All the extracted Dataframes are combined together using Pandas Concat function, by ignoring indexes.\n",
    "API_concat_rawDF=pd.concat([API_rawDF_0, API_rawDF_1,API_rawDF_2,API_rawDF_3,API_rawDF_4,API_rawDF_5,API_rawDF_6,\n",
    "          API_rawDF_7,API_rawDF_8],ignore_index=True)\n",
    "API_concat_rawDF.name=\"API_concat_rawDF\"\n",
    "print(f\"The Shape of Combined Dataframe {API_concat_rawDF.name} is {API_concat_rawDF.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8870e9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyName</th>\n",
       "      <th>CrashDate</th>\n",
       "      <th>Fatals</th>\n",
       "      <th>Peds</th>\n",
       "      <th>Persons</th>\n",
       "      <th>St_Case</th>\n",
       "      <th>State</th>\n",
       "      <th>StateName</th>\n",
       "      <th>TotalVehicles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39421</th>\n",
       "      <td>DALLAS (113)</td>\n",
       "      <td>/Date(1639275300000-0500)/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>484151.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39422</th>\n",
       "      <td>HARRIS (201)</td>\n",
       "      <td>/Date(1638079200000-0500)/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>484152.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39423</th>\n",
       "      <td>RUNNELS (399)</td>\n",
       "      <td>/Date(1618696080000-0400)/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>484153.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39424</th>\n",
       "      <td>BEXAR (29)</td>\n",
       "      <td>/Date(1622213760000-0400)/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>484154.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39425</th>\n",
       "      <td>BEXAR (29)</td>\n",
       "      <td>/Date(1627749180000-0400)/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>484155.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CountyName                   CrashDate  Fatals  Peds  Persons  \\\n",
       "39421   DALLAS (113)  /Date(1639275300000-0500)/     1.0   1.0      1.0   \n",
       "39422   HARRIS (201)  /Date(1638079200000-0500)/     1.0   0.0      2.0   \n",
       "39423  RUNNELS (399)  /Date(1618696080000-0400)/     1.0   0.0      4.0   \n",
       "39424     BEXAR (29)  /Date(1622213760000-0400)/     1.0   0.0      3.0   \n",
       "39425     BEXAR (29)  /Date(1627749180000-0400)/     1.0   1.0      1.0   \n",
       "\n",
       "        St_Case  State StateName  TotalVehicles  \n",
       "39421  484151.0   48.0     Texas            1.0  \n",
       "39422  484152.0   48.0     Texas            2.0  \n",
       "39423  484153.0   48.0     Texas            2.0  \n",
       "39424  484154.0   48.0     Texas            2.0  \n",
       "39425  484155.0   48.0     Texas            1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing last 5 rows from the Combined dataframe\n",
    "API_concat_rawDF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0e131",
   "metadata": {},
   "source": [
    "### Transformation 2: Checking for Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dd095d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_Nulls(df,col):\n",
    "    \"\"\"\n",
    "    This function checks the number of nulls in a columnof dataframe.\n",
    "    Input: Takes the name of dataframe and the column name\n",
    "    Returns: The count of nulls in the column\n",
    "    \"\"\"\n",
    "    col_nan=df[col].isnull().sum()\n",
    "    print(f\"The column {col} has {col_nan} nulls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5cd83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column CountyName has 0 nulls\n",
      "The column CrashDate has 0 nulls\n",
      "The column Fatals has 0 nulls\n",
      "The column Peds has 0 nulls\n",
      "The column Persons has 0 nulls\n",
      "The column St_Case has 0 nulls\n",
      "The column State has 0 nulls\n",
      "The column StateName has 0 nulls\n",
      "The column TotalVehicles has 0 nulls\n"
     ]
    }
   ],
   "source": [
    "for col in API_concat_rawDF.columns:\n",
    "    check_Nulls(API_concat_rawDF,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d4b33",
   "metadata": {},
   "source": [
    "### Transformation 3: Change column names to upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1cd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colnames_toUpper(df):\n",
    "    \"\"\"\n",
    "    This function takes Dataframe name as input and converts the Column names to UPPER Case.\n",
    "    \"\"\"\n",
    "    # Looping through each columns\n",
    "    for col in df.columns:\n",
    "        # Doing a inplace replace to convert column names to Upper case\n",
    "        df.rename(columns = {col:col.upper()}, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1afdcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of API_concat_rawDF are : Index(['COUNTYNAME', 'CRASHDATE', 'FATALS', 'PEDS', 'PERSONS', 'ST_CASE',\n",
      "       'STATE', 'STATENAME', 'TOTALVEHICLES'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Calling the function to convert the column names to Upper case.\n",
    "API_concat_rawDF=colnames_toUpper(API_concat_rawDF)\n",
    "print(f\"The columns of {API_concat_rawDF.name} are : {API_concat_rawDF.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0700aa6",
   "metadata": {},
   "source": [
    "### Transformation 4: Convert to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb89f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_number(df,col):\n",
    "    \"\"\"\n",
    "    This function takes dataframe name and column name as input and converts the values to Number. \n",
    "    It performs an inplace update.\n",
    "    \"\"\"\n",
    "    df[col]=df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fa816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of columns that contains Numeric values\n",
    "number_cols=[\"FATALS\",\"PEDS\",\"PERSONS\",\"ST_CASE\",\"STATE\",\"TOTALVEHICLES\"]\n",
    "# Looping through the list of numeric columns to convert the values to number\n",
    "for col in number_cols:\n",
    "    convert_to_number(API_concat_rawDF,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5487aae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTYNAME</th>\n",
       "      <th>CRASHDATE</th>\n",
       "      <th>FATALS</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATENAME</th>\n",
       "      <th>TOTALVEHICLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST. CLAIR (115)</td>\n",
       "      <td>/Date(1613185800000-0500)/</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JEFFERSON (73)</td>\n",
       "      <td>/Date(1613084400000-0500)/</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JEFFERSON (73)</td>\n",
       "      <td>/Date(1612675200000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHELBY (117)</td>\n",
       "      <td>/Date(1612387200000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JEFFERSON (73)</td>\n",
       "      <td>/Date(1612063200000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        COUNTYNAME                   CRASHDATE  FATALS  PEDS  PERSONS  \\\n",
       "0  ST. CLAIR (115)  /Date(1613185800000-0500)/       2     0        3   \n",
       "1   JEFFERSON (73)  /Date(1613084400000-0500)/       2     0        2   \n",
       "2   JEFFERSON (73)  /Date(1612675200000-0500)/       1     1        1   \n",
       "3     SHELBY (117)  /Date(1612387200000-0500)/       1     0        1   \n",
       "4   JEFFERSON (73)  /Date(1612063200000-0500)/       1     0        4   \n",
       "\n",
       "   ST_CASE  STATE STATENAME  TOTALVEHICLES  \n",
       "0    10001      1   Alabama              2  \n",
       "1    10002      1   Alabama              1  \n",
       "2    10003      1   Alabama              1  \n",
       "3    10004      1   Alabama              1  \n",
       "4    10005      1   Alabama              2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing sample rows to validate the Number conversion\n",
    "API_concat_rawDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf0953",
   "metadata": {},
   "source": [
    "### Transformation 5: Convert to Upper Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1fd5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toUpper(df,col):\n",
    "    \"\"\"\n",
    "    This fnction converts all the values in the given column of dataframe to Upper case and removes extra spaces from the string..\n",
    "    Inputs: Dataframe name and Column Name.\n",
    "    Performs an inplace update by converting to Upper case and removing extra spaces.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using apply method to convert to UpperCase and strip spaces.\n",
    "        df[col]=df[col].apply(str.strip)\n",
    "        df[col]=df[col].apply(str.upper)\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0760e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of columns that contains String values\n",
    "str_cols=[\"COUNTYNAME\",\"STATENAME\"]\n",
    "# Looping through the list of String columns to convert the values to Upper case\n",
    "for col in str_cols:\n",
    "    toUpper(API_concat_rawDF,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f7950",
   "metadata": {},
   "source": [
    "### Transformation 6: Adding new column by extracting county number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee612c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the combined dataframe before adding new column\n",
    "API_concat_df1=API_concat_rawDF.copy()\n",
    "# Extracting county number from the CountyName column by extracting the Numbers using Regular Expressions\n",
    "API_concat_df1[\"COUNTY\"]=API_concat_df1[\"COUNTYNAME\"].str.extract('(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdfe099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTYNAME</th>\n",
       "      <th>CRASHDATE</th>\n",
       "      <th>FATALS</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATENAME</th>\n",
       "      <th>TOTALVEHICLES</th>\n",
       "      <th>COUNTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST. CLAIR (115)</td>\n",
       "      <td>/Date(1613185800000-0500)/</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JEFFERSON (73)</td>\n",
       "      <td>/Date(1613084400000-0500)/</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JEFFERSON (73)</td>\n",
       "      <td>/Date(1612675200000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHELBY (117)</td>\n",
       "      <td>/Date(1612387200000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JEFFERSON (73)</td>\n",
       "      <td>/Date(1612063200000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        COUNTYNAME                   CRASHDATE  FATALS  PEDS  PERSONS  \\\n",
       "0  ST. CLAIR (115)  /Date(1613185800000-0500)/       2     0        3   \n",
       "1   JEFFERSON (73)  /Date(1613084400000-0500)/       2     0        2   \n",
       "2   JEFFERSON (73)  /Date(1612675200000-0500)/       1     1        1   \n",
       "3     SHELBY (117)  /Date(1612387200000-0500)/       1     0        1   \n",
       "4   JEFFERSON (73)  /Date(1612063200000-0500)/       1     0        4   \n",
       "\n",
       "   ST_CASE  STATE STATENAME  TOTALVEHICLES COUNTY  \n",
       "0    10001      1   ALABAMA              2    115  \n",
       "1    10002      1   ALABAMA              1     73  \n",
       "2    10003      1   ALABAMA              1     73  \n",
       "3    10004      1   ALABAMA              1    117  \n",
       "4    10005      1   ALABAMA              2     73  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing top 5 rows to verify the newly added column\n",
    "API_concat_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a243f2",
   "metadata": {},
   "source": [
    "### Transformation 7: Cleansing CountyName using Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2924cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match(input_str):\n",
    "    \"\"\"\n",
    "    This function uses RegEx to match the Pattern defined and returns the matched data.\n",
    "    If no match is found, values are skipped.\n",
    "    \"\"\"\n",
    "    # If no match is found with pattern, values are skipped\n",
    "    if pattern.search(input_str)==None:\n",
    "        pass\n",
    "    else:\n",
    "        # Returns the data that matches the pattern\n",
    "        return pattern.search(input_str).group()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08c05593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pattern to extract the County name which can include Alphabets, Underscore and period\n",
    "pattern=re.compile(r'[a-zA-Z\\.\\-\\_ ]+')\n",
    "# Inplace Replace is done on the column CountyName to identify the values that matches the Pattern\n",
    "API_concat_df1[\"COUNTYNAME\"]=API_concat_df1[\"COUNTYNAME\"].apply(find_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447088a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTYNAME</th>\n",
       "      <th>CRASHDATE</th>\n",
       "      <th>FATALS</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATENAME</th>\n",
       "      <th>TOTALVEHICLES</th>\n",
       "      <th>COUNTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39421</th>\n",
       "      <td>DALLAS</td>\n",
       "      <td>/Date(1639275300000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>484151</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39422</th>\n",
       "      <td>HARRIS</td>\n",
       "      <td>/Date(1638079200000-0500)/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>484152</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39423</th>\n",
       "      <td>RUNNELS</td>\n",
       "      <td>/Date(1618696080000-0400)/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>484153</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39424</th>\n",
       "      <td>BEXAR</td>\n",
       "      <td>/Date(1622213760000-0400)/</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>484154</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39425</th>\n",
       "      <td>BEXAR</td>\n",
       "      <td>/Date(1627749180000-0400)/</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>484155</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COUNTYNAME                   CRASHDATE  FATALS  PEDS  PERSONS  ST_CASE  \\\n",
       "39421    DALLAS   /Date(1639275300000-0500)/       1     1        1   484151   \n",
       "39422    HARRIS   /Date(1638079200000-0500)/       1     0        2   484152   \n",
       "39423   RUNNELS   /Date(1618696080000-0400)/       1     0        4   484153   \n",
       "39424     BEXAR   /Date(1622213760000-0400)/       1     0        3   484154   \n",
       "39425     BEXAR   /Date(1627749180000-0400)/       1     1        1   484155   \n",
       "\n",
       "       STATE STATENAME  TOTALVEHICLES COUNTY  \n",
       "39421     48     TEXAS              1    113  \n",
       "39422     48     TEXAS              2    201  \n",
       "39423     48     TEXAS              2    399  \n",
       "39424     48     TEXAS              2     29  \n",
       "39425     48     TEXAS              1     29  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing 5 rows to verify the newly added column\n",
    "API_concat_df1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c020e",
   "metadata": {},
   "source": [
    "### Transformation 8: Cleansing Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a75ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pattern for the default Dates in the CrashDate field.\n",
    "# The value \"hyphen\" as first character represents invalid date, which will be defaulted in next step.\n",
    "pattern2=re.compile(r'-[0-9]+-[0-9]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61ffc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match2(input_date):\n",
    "    \"\"\"\n",
    "    This function will find the matching pattern of dates with hyphen in the start and return a default date.\n",
    "    If no match is found, same date value is returned as the input date.\n",
    "    \"\"\"\n",
    "    # If no matches are found, input date is returned\n",
    "    if pattern2.search(input_date)==None:\n",
    "        return input_date\n",
    "    # If match with pattern2 is found, any of the below default dates will be picked. These are dates from \n",
    "    # last dates of the month. There are about 300 invalid dates in the entire dataset returned by the API\n",
    "    else:\n",
    "        # Default dates representing last dates of each month in 2021 in epoch format\n",
    "        default_dates=[\"1612137599000-0500\",\"1614556799000-0500\",\"1617235199000-0500\",\"1619827199000-0500\",\n",
    "               \"1622505599000-0500\",\"1625097599000-0500\",\"1627775999000-0500\",\"1630454399000-0500\",\n",
    "               \"1633046399000-0500\",\"1635724799000-0500\",\"1638316799000-0500\",\"1640995199000-0500\"\n",
    "              ]\n",
    "        # A random date will be picked from above list which will be used to represent default value\n",
    "        random_default_date=np.random.choice(default_dates)\n",
    "        return random_default_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2939621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The find match2 function is applied to column Crash date and an inplace update is done\n",
    "API_concat_df1[\"CRASHDATE\"]=API_concat_df1[\"CRASHDATE\"].apply(find_match2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf274b1",
   "metadata": {},
   "source": [
    "### Transformation 9: Converting Epoch Date to Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "152d0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pattern3 represents valid date format.\n",
    "pattern3='(\\d+-\\d+)'\n",
    "# The valid dates are extracted from the CRASH date field. In place update is done\n",
    "API_concat_df1[\"CRASHDATE\"]=API_concat_df1[\"CRASHDATE\"].str.extract(pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afb482ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTYNAME</th>\n",
       "      <th>CRASHDATE</th>\n",
       "      <th>FATALS</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATENAME</th>\n",
       "      <th>TOTALVEHICLES</th>\n",
       "      <th>COUNTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39421</th>\n",
       "      <td>DALLAS</td>\n",
       "      <td>1639275300000-0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>484151</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39422</th>\n",
       "      <td>HARRIS</td>\n",
       "      <td>1638079200000-0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>484152</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39423</th>\n",
       "      <td>RUNNELS</td>\n",
       "      <td>1618696080000-0400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>484153</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39424</th>\n",
       "      <td>BEXAR</td>\n",
       "      <td>1622213760000-0400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>484154</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39425</th>\n",
       "      <td>BEXAR</td>\n",
       "      <td>1627749180000-0400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>484155</td>\n",
       "      <td>48</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COUNTYNAME           CRASHDATE  FATALS  PEDS  PERSONS  ST_CASE  STATE  \\\n",
       "39421    DALLAS   1639275300000-0500       1     1        1   484151     48   \n",
       "39422    HARRIS   1638079200000-0500       1     0        2   484152     48   \n",
       "39423   RUNNELS   1618696080000-0400       1     0        4   484153     48   \n",
       "39424     BEXAR   1622213760000-0400       1     0        3   484154     48   \n",
       "39425     BEXAR   1627749180000-0400       1     1        1   484155     48   \n",
       "\n",
       "      STATENAME  TOTALVEHICLES COUNTY  \n",
       "39421     TEXAS              1    113  \n",
       "39422     TEXAS              2    201  \n",
       "39423     TEXAS              2    399  \n",
       "39424     TEXAS              2     29  \n",
       "39425     TEXAS              1     29  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing 5 rows of date after extracting and cleansing the date.\n",
    "API_concat_df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40c2e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_epoch_date(input_date):\n",
    "    \"\"\"\n",
    "    This function is to treat the date which is in Epoch format to Timestamp format \n",
    "    and also converts to local timezone.\n",
    "    \"\"\"\n",
    "    # The epoch date is split and then last 3 digits are ignored.\n",
    "    input_date_part1=int(input_date.split(\"-\")[0])/1000\n",
    "    # The second part of the epoch date contains the timezone, which is extracted and \n",
    "    # converted to seconds by multiplying the number of hours with 3600\n",
    "    input_date_part2=int(input_date.split(\"-\")[1])/100*3600\n",
    "    # The difference between the both extracted times is calculated which will then be converted to \n",
    "    # Datetime format using pandas to_datetime method\n",
    "    epoch_date=input_date_part1-input_date_part2\n",
    "    return pd.to_datetime(epoch_date,unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9b50be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COnvert to epoch function is applied to Crashdate and an inplace update is done.\n",
    "API_concat_df1[\"CRASHDATE\"]=API_concat_df1[\"CRASHDATE\"].apply(convert_epoch_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45985ecf",
   "metadata": {},
   "source": [
    "### Transformation 10: Changing the timestamp format and order of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d81744f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the column to datetime format\n",
    "API_concat_df1[\"CRASHDATE\"] = pd.to_datetime(API_concat_df1[\"CRASHDATE\"])\n",
    "# Changing the format of CrashDate by removing the seconds as it is not included in the data.\n",
    "API_concat_df1[\"CRASHDATE\"]=API_concat_df1[\"CRASHDATE\"].dt.strftime('%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35ae596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating final dataframe by rearranging the columns which will be used to join with other dataframes\n",
    "# in the final milestone to create Visualizations\n",
    "API_final_df=API_concat_df1[[\"ST_CASE\",\"STATE\",\"STATENAME\",\"COUNTY\",\"COUNTYNAME\",\"CRASHDATE\"\n",
    "                               ,\"FATALS\",\"PEDS\",\"PERSONS\",\"TOTALVEHICLES\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411794c9",
   "metadata": {},
   "source": [
    "### Transformation 11: GroupBy and Sort Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "472c3a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATENAME\n",
       "TEXAS                   4476\n",
       "CALIFORNIA              4270\n",
       "FLORIDA                 3733\n",
       "GEORGIA                 1794\n",
       "NORTH CAROLINA          1658\n",
       "                        ... \n",
       "HAWAII                    94\n",
       "VERMONT                   74\n",
       "ALASKA                    67\n",
       "RHODE ISLAND              63\n",
       "DISTRICT OF COLUMBIA      41\n",
       "Name: FATALS, Length: 51, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Doing a group by on date to find the states with most Fatalities\n",
    "API_fatals_df=API_final_df.groupby([\"STATENAME\"],sort=True)[\"FATALS\"].sum().sort_values(ascending=False)\n",
    "display(API_fatals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11a451",
   "metadata": {},
   "source": [
    "### Transformation 12: GroupBy and Sort Transformations on Crash Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c76a9b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRASH_MONTH\n",
       "Aug    416\n",
       "Oct    416\n",
       "Dec    408\n",
       "Sep    400\n",
       "Jul    395\n",
       "Mar    375\n",
       "Nov    370\n",
       "Apr    364\n",
       "May    359\n",
       "Jun    357\n",
       "Jan    353\n",
       "Feb    263\n",
       "Name: FATALS, dtype: int32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a subset Dataframe that contains Texas records\n",
    "API_TX_df=API_final_df[API_final_df[\"STATENAME\"].isin([\"TEXAS\"])]\n",
    "# Adding a new column \"Crash_Month\" that includes the details of the month when the Crash occurred\n",
    "API_TX_df[\"CRASH_MONTH\"]=pd.to_datetime(API_TX_df[\"CRASHDATE\"]).dt.strftime('%b')\n",
    "# Doing a GroupBy on Crash Month and Sort in Descending to identify the \n",
    "# Months when Most crashes occurred in Texas\n",
    "API_TX_df.groupby([\"CRASH_MONTH\"],sort=True)[\"FATALS\"].sum().sort_values(ascending=False)\n",
    "# Results suggest that August and October were deadliest months followed by December of 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3f62d",
   "metadata": {},
   "source": [
    "## 3. Displaying data of the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d5074c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST_CASE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATENAME</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>COUNTYNAME</th>\n",
       "      <th>CRASHDATE</th>\n",
       "      <th>FATALS</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>TOTALVEHICLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>115</td>\n",
       "      <td>ST. CLAIR</td>\n",
       "      <td>2021-02-12 22:10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-02-11 18:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-02-07 00:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>117</td>\n",
       "      <td>SHELBY</td>\n",
       "      <td>2021-02-03 16:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-01-30 22:20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10006</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>2021-01-28 12:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10007</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>83</td>\n",
       "      <td>LIMESTONE</td>\n",
       "      <td>2021-01-27 22:25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10008</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>125</td>\n",
       "      <td>TUSCALOOSA</td>\n",
       "      <td>2021-01-23 02:44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10009</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>101</td>\n",
       "      <td>MONTGOMERY</td>\n",
       "      <td>2021-01-17 00:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10010</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-01-20 00:01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10011</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-01-15 13:25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10012</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>43</td>\n",
       "      <td>CULLMAN</td>\n",
       "      <td>2021-01-14 19:45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10013</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>97</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>2021-01-01 05:36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10014</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>31</td>\n",
       "      <td>COFFEE</td>\n",
       "      <td>2021-01-01 01:08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10015</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-01-01 02:03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10016</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-01-01 02:09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10017</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>83</td>\n",
       "      <td>LIMESTONE</td>\n",
       "      <td>2021-01-01 01:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10018</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>15</td>\n",
       "      <td>CALHOUN</td>\n",
       "      <td>2021-01-01 18:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10019</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>57</td>\n",
       "      <td>FAYETTE</td>\n",
       "      <td>2021-01-01 19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10020</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>125</td>\n",
       "      <td>TUSCALOOSA</td>\n",
       "      <td>2021-01-03 08:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10021</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-01-04 13:09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10022</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>97</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>2021-01-04 18:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10023</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>51</td>\n",
       "      <td>ELMORE</td>\n",
       "      <td>2021-01-05 22:55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10024</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>97</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>2021-01-05 03:50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10025</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>59</td>\n",
       "      <td>FRANKLIN</td>\n",
       "      <td>2021-01-06 07:45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10026</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>31</td>\n",
       "      <td>COFFEE</td>\n",
       "      <td>2021-01-06 18:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10027</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>81</td>\n",
       "      <td>LEE</td>\n",
       "      <td>2021-01-06 18:25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10028</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>43</td>\n",
       "      <td>CULLMAN</td>\n",
       "      <td>2021-01-06 23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10029</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>31</td>\n",
       "      <td>COFFEE</td>\n",
       "      <td>2021-01-06 23:45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10030</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>79</td>\n",
       "      <td>LAWRENCE</td>\n",
       "      <td>2021-01-07 07:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10031</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>127</td>\n",
       "      <td>WALKER</td>\n",
       "      <td>2021-01-07 16:53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10032</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>103</td>\n",
       "      <td>MORGAN</td>\n",
       "      <td>2021-01-07 15:24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10033</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>73</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>2021-01-08 10:13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10034</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>121</td>\n",
       "      <td>TALLADEGA</td>\n",
       "      <td>2021-01-08 13:18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10035</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>109</td>\n",
       "      <td>PIKE</td>\n",
       "      <td>2021-01-08 10:50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10036</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>97</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>2021-01-08 20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10037</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>97</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>2021-01-08 23:30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10038</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>115</td>\n",
       "      <td>ST. CLAIR</td>\n",
       "      <td>2021-01-09 02:01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10039</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTAUGA</td>\n",
       "      <td>2021-01-09 13:47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10040</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>85</td>\n",
       "      <td>LOWNDES</td>\n",
       "      <td>2021-01-10 00:32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10041</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>117</td>\n",
       "      <td>SHELBY</td>\n",
       "      <td>2021-01-10 19:40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10042</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>49</td>\n",
       "      <td>DEKALB</td>\n",
       "      <td>2021-01-10 16:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10043</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>97</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>2021-01-10 19:53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10044</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>117</td>\n",
       "      <td>SHELBY</td>\n",
       "      <td>2021-01-11 12:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10045</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>103</td>\n",
       "      <td>MORGAN</td>\n",
       "      <td>2021-01-14 11:36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10046</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>81</td>\n",
       "      <td>LEE</td>\n",
       "      <td>2021-01-15 16:51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10047</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>89</td>\n",
       "      <td>MADISON</td>\n",
       "      <td>2021-01-16 02:10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10048</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>131</td>\n",
       "      <td>WILCOX</td>\n",
       "      <td>2021-01-16 20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10049</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>89</td>\n",
       "      <td>MADISON</td>\n",
       "      <td>2021-01-16 18:16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10050</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>15</td>\n",
       "      <td>CALHOUN</td>\n",
       "      <td>2021-01-17 19:57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ST_CASE  STATE STATENAME COUNTY   COUNTYNAME         CRASHDATE  FATALS  \\\n",
       "0     10001      1   ALABAMA    115   ST. CLAIR   2021-02-12 22:10       2   \n",
       "1     10002      1   ALABAMA     73   JEFFERSON   2021-02-11 18:00       2   \n",
       "2     10003      1   ALABAMA     73   JEFFERSON   2021-02-07 00:20       1   \n",
       "3     10004      1   ALABAMA    117      SHELBY   2021-02-03 16:20       1   \n",
       "4     10005      1   ALABAMA     73   JEFFERSON   2021-01-30 22:20       1   \n",
       "5     10006      1   ALABAMA      1     AUTAUGA   2021-01-28 12:15       1   \n",
       "6     10007      1   ALABAMA     83   LIMESTONE   2021-01-27 22:25       1   \n",
       "7     10008      1   ALABAMA    125  TUSCALOOSA   2021-01-23 02:44       1   \n",
       "8     10009      1   ALABAMA    101  MONTGOMERY   2021-01-17 00:32       1   \n",
       "9     10010      1   ALABAMA     73   JEFFERSON   2021-01-20 00:01       1   \n",
       "10    10011      1   ALABAMA     73   JEFFERSON   2021-01-15 13:25       1   \n",
       "11    10012      1   ALABAMA     43     CULLMAN   2021-01-14 19:45       1   \n",
       "12    10013      1   ALABAMA     97      MOBILE   2021-01-01 05:36       1   \n",
       "13    10014      1   ALABAMA     31      COFFEE   2021-01-01 01:08       1   \n",
       "14    10015      1   ALABAMA     73   JEFFERSON   2021-01-01 02:03       1   \n",
       "15    10016      1   ALABAMA     73   JEFFERSON   2021-01-01 02:09       1   \n",
       "16    10017      1   ALABAMA     83   LIMESTONE   2021-01-01 01:30       1   \n",
       "17    10018      1   ALABAMA     15     CALHOUN   2021-01-01 18:50       1   \n",
       "18    10019      1   ALABAMA     57     FAYETTE   2021-01-01 19:00       1   \n",
       "19    10020      1   ALABAMA    125  TUSCALOOSA   2021-01-03 08:19       1   \n",
       "20    10021      1   ALABAMA     73   JEFFERSON   2021-01-04 13:09       1   \n",
       "21    10022      1   ALABAMA     97      MOBILE   2021-01-04 18:50       1   \n",
       "22    10023      1   ALABAMA     51      ELMORE   2021-01-05 22:55       2   \n",
       "23    10024      1   ALABAMA     97      MOBILE   2021-01-05 03:50       1   \n",
       "24    10025      1   ALABAMA     59    FRANKLIN   2021-01-06 07:45       1   \n",
       "25    10026      1   ALABAMA     31      COFFEE   2021-01-06 18:15       1   \n",
       "26    10027      1   ALABAMA     81         LEE   2021-01-06 18:25       1   \n",
       "27    10028      1   ALABAMA     43     CULLMAN   2021-01-06 23:00       1   \n",
       "28    10029      1   ALABAMA     31      COFFEE   2021-01-06 23:45       1   \n",
       "29    10030      1   ALABAMA     79    LAWRENCE   2021-01-07 07:05       1   \n",
       "30    10031      1   ALABAMA    127      WALKER   2021-01-07 16:53       1   \n",
       "31    10032      1   ALABAMA    103      MORGAN   2021-01-07 15:24       1   \n",
       "32    10033      1   ALABAMA     73   JEFFERSON   2021-01-08 10:13       1   \n",
       "33    10034      1   ALABAMA    121   TALLADEGA   2021-01-08 13:18       1   \n",
       "34    10035      1   ALABAMA    109        PIKE   2021-01-08 10:50       1   \n",
       "35    10036      1   ALABAMA     97      MOBILE   2021-01-08 20:00       1   \n",
       "36    10037      1   ALABAMA     97      MOBILE   2021-01-08 23:30       2   \n",
       "37    10038      1   ALABAMA    115   ST. CLAIR   2021-01-09 02:01       1   \n",
       "38    10039      1   ALABAMA      1     AUTAUGA   2021-01-09 13:47       1   \n",
       "39    10040      1   ALABAMA     85     LOWNDES   2021-01-10 00:32       1   \n",
       "40    10041      1   ALABAMA    117      SHELBY   2021-01-10 19:40       1   \n",
       "41    10042      1   ALABAMA     49      DEKALB   2021-01-10 16:30       1   \n",
       "42    10043      1   ALABAMA     97      MOBILE   2021-01-10 19:53       1   \n",
       "43    10044      1   ALABAMA    117      SHELBY   2021-01-11 12:15       1   \n",
       "44    10045      1   ALABAMA    103      MORGAN   2021-01-14 11:36       1   \n",
       "45    10046      1   ALABAMA     81         LEE   2021-01-15 16:51       1   \n",
       "46    10047      1   ALABAMA     89     MADISON   2021-01-16 02:10       1   \n",
       "47    10048      1   ALABAMA    131      WILCOX   2021-01-16 20:00       1   \n",
       "48    10049      1   ALABAMA     89     MADISON   2021-01-16 18:16       1   \n",
       "49    10050      1   ALABAMA     15     CALHOUN   2021-01-17 19:57       1   \n",
       "\n",
       "    PEDS  PERSONS  TOTALVEHICLES  \n",
       "0      0        3              2  \n",
       "1      0        2              1  \n",
       "2      1        1              1  \n",
       "3      0        1              1  \n",
       "4      0        4              2  \n",
       "5      0        3              3  \n",
       "6      0        1              1  \n",
       "7      0        2              2  \n",
       "8      0        2              1  \n",
       "9      0        3              3  \n",
       "10     0        3              2  \n",
       "11     0        4              2  \n",
       "12     0        2              2  \n",
       "13     1        2              1  \n",
       "14     1        1              1  \n",
       "15     0        1              1  \n",
       "16     0        1              1  \n",
       "17     1        2              1  \n",
       "18     0        1              1  \n",
       "19     0        1              1  \n",
       "20     0        1              1  \n",
       "21     1        1              1  \n",
       "22     0        2              1  \n",
       "23     0        2              1  \n",
       "24     0        2              2  \n",
       "25     0        4              2  \n",
       "26     0        5              3  \n",
       "27     0        2              2  \n",
       "28     0        1              1  \n",
       "29     0        3              2  \n",
       "30     0        1              1  \n",
       "31     0        4              2  \n",
       "32     0        1              1  \n",
       "33     0        1              1  \n",
       "34     0        2              1  \n",
       "35     0        1              1  \n",
       "36     0        3              2  \n",
       "37     0        2              1  \n",
       "38     0        4              2  \n",
       "39     0        1              1  \n",
       "40     0        1              1  \n",
       "41     1        2              2  \n",
       "42     0        2              2  \n",
       "43     0        1              1  \n",
       "44     0        1              1  \n",
       "45     0        2              2  \n",
       "46     0        1              1  \n",
       "47     0        2              1  \n",
       "48     1        1              1  \n",
       "49     1        1              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing top 50 columns of final Dataframe\n",
    "display(API_final_df.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af0664",
   "metadata": {},
   "source": [
    "## 4. Ethical Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f649e3",
   "metadata": {},
   "source": [
    "##### a. Maximum number of vehicles involved in the accident is restricted to six vehicles. Hence, this study does not include crashes that involved more than 6 vehicles and pileups. This should be taken into consideration while deriving conclusions from the research.\n",
    "##### b. All the rows in the dataset represents the crashes that had atleast one fatality. Hence the research does not include the details of non-fatal accidents. The grim results  of this research must be studied with empathy.\n",
    "##### c. Some crashes did not had include the time of crash and hence they were replaced with default values. There were about 300 such instances. Hence, the results cannot be derived only based on the time of crash as about 1% of data contains default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6db1bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_final_df.to_excel('formatted_APIdata_df.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
